= Validating the environment
include::_attributes.adoc[]

Now that you are connected to your workbench, let's make sure that all the expected services are responding properly in the cluster.

When you open your workbench you will see your "Launcher" tab:

. At the bottom of the page under "Other", click on "Terminal":
+
[.bordershadow]
image::02/terminal.png[]
+
.. Run the following command to download a `.env` file that will be used by the Jupiter Notebooks to configure access to the Azure AI services
+

[.lines_space]
[.console-input]
[source, bash, subs="attributes+"]
cd
wget {azure_ai_info_url}
cat .env

. The `.env` file that is downloaded will look something like the following (but configured for your enviornment).  Note there are no credentials in it.  That is because the Azure Python SDK will use Azure Managed Identity (via OIDC) to authenticate your pods which are running under a trusted `ServiceAccount`, We'll finish up this trust relationship shortly.
+

[.lines_space]
[.console-input]
[source, bash, subs="attributes+"]
AZURE_OPENAI_ENDPOINT=https://my-ai-service.cognitiveservices.azure.com/
OPENAI_API_VERSION=2024-12-01-preview
AZURE_DEPLOYMENT=gpt-4
AZURE_EMBEDDING=text-embeddings
AZURE_AI_SEARCH_SERVICE_NAME="my-ai-search"
AZURE_AI_SEARCH_INDEX_NAME="my-ai-index"


. When configuring Managed Identity, you need to create an Azure Managed Identity for the workload to use, Attach approprite roles and scopes to give it access to Azure resources, and then create a Federated Identity which creates the trust relationship between the Identity and the OpenShift ServiceAccount that will be running your `pods`.
+

**Do not run the following commands** they have already been run for you, and are shown here to show you the Managed Identity relationship setup.
+

[.lines_space]
[.console-input]
[source, bash, subs="attributes+"]
# az identity create --name "${user}-id" --resource-group "aro"
# export OBJECT_ID="$(az identity show --name "${user}-id" \
#    --resource-group "aro" --query 'principalId' -otsv)"
# export CLIENT_ID="$(az identity show --name "${user}-id" \
#    --resource-group "aro" --query 'clientId' -otsv)"
# export AI_SEARCH_SCOPE="/subscriptions/XXX/resourceGroups/aro-ai/providers/Microsoft.Search/searchServices/ai"
# export AI_SCOPE="/subscriptions/XXX/resourceGroups/aro-ai/providers/Microsoft.CognitiveServices/accounts/ai"
# az role assignment create --assignee-object-id "${OBJECT_ID}" \
#    --role "Search Index Data Reader" \
#    --scope "$AI_SEARCH_SCOPE" \
#    --assignee-principal-type ServicePrincipal
# az role assignment create --assignee-object-id "${OBJECT_ID}" \
#    --role "Cognitive Services OpenAI User" \
#    --scope "$AI_SCOPE" \
#    --assignee-principal-type ServicePrincipal

. This final command, which you will run in your terminal will annotate the `my-workbench` service account which the Jupyter Notebook, and later your deployed application will use to authenticate to the Azure services following the trust relationship built in the previous command.
+

[.lines_space]
[.console-input]
[source, bash, subs="attributes+"]
oc -n {user} annotate sa my-workbench \
  azure.workload.identity/client-id={user_assigned_identity_client_id}
oc -n {user} rollout restart statefulset my-workbench

. After a moment you'll get a message that says **"Server unavailable or unreachable
Your server at /notebook/{user}/my-workbench/ is not running. Would you like to restart it?"**, This is because the Jupyter notebook is restarting so that it can use the Azure Managed Identity that we just linked to the service account.  Wait a minute or so and then refresh your browser window.

. In the left hand navigation menu, navigate to the folder called: `parasol-insurance/lab-materials/02`

. Open the notebook called `02-05-validating.ipynb`

. If you have never executed Cells in a Jupyter Notebook before, here is what you need to do:

.. Click on the **Restart kernel and Run all Cells** link:
+
[.bordershadow]
image::02/02-05-restart-and-run.png[]
.. Click **Restart** :
+
[.bordershadow]
image::02/02-05-restart-kernel.png[]
+
. Running these cells will confirm that all the lab-required services are responding.

The output should look as follows:

[source,console]
----
Found Azure OpenAI Base Endpoint: https://eastus.api.cognitive.microsoft.com/
Success: LLM Service-FlanT5 is reachable on llm-flant5.ic-shared-llm.svc.cluster.local:3000
----

If the output of this notebook looks suspicious, please inform the people leading the {ic}.

== Overall view

This is a summarized visualization of how the environment is laid out (in some workshops a local PostgreSQL database will be used instead of Azure PostgreSQL):

[.bordershadow]
image::02/ic-eng-diag.drawio.png[]
